{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eminem_Bot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o91q8imJuAbw"
      },
      "source": [
        "# Preamble\n",
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pymj94E97pam"
      },
      "source": [
        "# Path of the text file containing the training data\n",
        "training_data_file = 'Eminem_songs_lyrics.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEvKvTTd7vMq"
      },
      "source": [
        "def remove_punctuation(sentence):\n",
        "    return sentence.translate(str.maketrans('','', string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFt3A-L-YMLX"
      },
      "source": [
        "O(len(sentence)) --> O(n)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw5Zv_i_7zS5"
      },
      "source": [
        "def add2dict(dictionary, key, value):\n",
        "    if key not in dictionary:\n",
        "        dictionary[key] = []\n",
        "    dictionary[key].append(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp8t2bwuYMLY"
      },
      "source": [
        "O(1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBKuNnCn71OX"
      },
      "source": [
        "def list2probabilitydict(given_list):\n",
        "    probability_dict = {}\n",
        "    given_list_length = len(given_list)\n",
        "    for item in given_list:\n",
        "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
        "    for key, value in probability_dict.items():\n",
        "        probability_dict[key] = value / given_list_length\n",
        "    return probability_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zuG1ckMYMLY"
      },
      "source": [
        "O(n)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lvvet4t73ip"
      },
      "source": [
        "initial_word = {}\n",
        "second_word = {}\n",
        "transitions = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAxyGHHN75VN"
      },
      "source": [
        "# Trains a Markov model based on the data in training_data_file\n",
        "def train_markov_model():\n",
        "    for line in open(training_data_file, encoding = \"utf8\"):\n",
        "        tokens = remove_punctuation(line.rstrip().lower()).split()\n",
        "        tokens_length = len(tokens)\n",
        "        for i in range(tokens_length):\n",
        "            token = tokens[i]\n",
        "            if i == 0:\n",
        "                initial_word[token] = initial_word.get(token, 0) + 1\n",
        "            else:\n",
        "                prev_token = tokens[i - 1]\n",
        "                if i == tokens_length - 1:\n",
        "                    add2dict(transitions, (prev_token, token), 'END')\n",
        "                if i == 1:\n",
        "                    add2dict(second_word, prev_token, token)\n",
        "                else:\n",
        "                    prev_prev_token = tokens[i - 2]\n",
        "                    add2dict(transitions, (prev_prev_token, prev_token), token)\n",
        "    \n",
        "    # Normalize the distributions\n",
        "    initial_word_total = sum(initial_word.values())\n",
        "    for key, value in initial_word.items():\n",
        "        initial_word[key] = value / initial_word_total\n",
        "        \n",
        "    for prev_word, next_word_list in second_word.items():\n",
        "        second_word[prev_word] = list2probabilitydict(next_word_list)\n",
        "        \n",
        "    for word_pair, next_word_list in transitions.items():\n",
        "        transitions[word_pair] = list2probabilitydict(next_word_list)\n",
        "    \n",
        "    print('Training successful.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_TDEKrvYMLa"
      },
      "source": [
        "inputs: sentences and words --> n and m\n",
        "## O(n * m)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1xDX_iG78Vv",
        "outputId": "0a49da35-bb3c-49af-918e-87d2d80fe0f5"
      },
      "source": [
        "train_markov_model()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI15xkJl7_OR"
      },
      "source": [
        "def sample_word(dictionary):\n",
        "   \n",
        "    p0 = np.random.random()\n",
        "    cumulative = 0\n",
        "    for key, value in dictionary.items():\n",
        "        cumulative += value\n",
        "        if p0 < cumulative:\n",
        "            return key\n",
        "    assert(False) # Check to make sure function return a key or a word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UF0X-GIYMLb"
      },
      "source": [
        "O(n) where n --> number of values in dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uuM9uhg8FyQ"
      },
      "source": [
        "# Function to generate sample text\n",
        "def generate(number_of_sentences):\n",
        "    for i in range(number_of_sentences):\n",
        "        sentence = []\n",
        "        # Initial word\n",
        "        word0 = sample_word(initial_word)\n",
        "        sentence.append(word0)\n",
        "        # Second word\n",
        "        word1 = sample_word(second_word[word0])\n",
        "        sentence.append(word1)\n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            word2 = sample_word(transitions[(word0, word1)])\n",
        "           # print(transitions[(word0, word1)])\n",
        "            if word2 == 'END':\n",
        "                break\n",
        "            sentence.append(word2)\n",
        "            word0 , word1 = word1, word2\n",
        "        print(' '.join(sentence))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62084_BTYMLc"
      },
      "source": [
        "Generate()\n",
        "number of sentences : n, len(dictionary), len(transitions[(word0, word1)] : m\n",
        "## O(n * m)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxgRxJOO8HxP",
        "outputId": "cf9e7eea-1cf3-40bf-b37d-bb41ce70a633"
      },
      "source": [
        "generate(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all my sins need holy water feel it washing over me\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPOrAaIG8JyP",
        "outputId": "22a13b5c-5faf-42e4-f8ad-a88ea79197a7"
      },
      "source": [
        "generate(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feel my wrath of attack\n",
            "cause i found a hella way to get em motivated\n",
            "hit the earth like an asteroid\n",
            "why do i do this dirt that i aint as big as i was gonna go easy on you like that\n",
            "i attempt these lyrical acrobat stunts while im masterfully constructing this masterpiece yeah\n",
            "hes choking how everybodys joking now\n",
            "stay in one spot another day of monotonys gotten me\n",
            "the souls escaping through this hole that is gaping\n",
            "cause you may be a god\n",
            "to meet rundmc and induct them\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvFJjt73YMLd"
      },
      "source": [
        "def get_max(dic):\n",
        "    p_end = dic.get('END', 0)\n",
        "    list_1 = sorted(dic, key= lambda x: dic[x], reverse = True)\n",
        "    p_max = dic[list_1[0]]\n",
        "    max_list = []\n",
        "    for item in list_1:\n",
        "        if dic[item] == p_max :\n",
        "            max_list.append(item)\n",
        "        else:\n",
        "            break\n",
        "    return np.random.choice(max_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieUJlDgKYMLd"
      },
      "source": [
        "## O(n * log(n)) due to the sorting and the loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgZ5UEx81cQ"
      },
      "source": [
        "def generate1(number_of_sentences):\n",
        "    for i in range(number_of_sentences):\n",
        "        sentence = []\n",
        "        # Initial word\n",
        "        word0 = sample_word(initial_word)\n",
        "        # print(initial_word)\n",
        "        sentence.append(word0)\n",
        "        # Second word\n",
        "        word1 = sample_word(second_word[word0])\n",
        "        sentence.append(word1)\n",
        "        # Subsequent words until END\n",
        "        while True:\n",
        "            word2 = get_max(transitions[(word0, word1)])\n",
        "       #     print(transitions[(word0, word1)])\n",
        "            if word2 == 'END' or word2 in [word0, word1]:\n",
        "                break\n",
        "            sentence.append(word2)\n",
        "            word0 = word1\n",
        "            word1 = word2\n",
        "        print(' '.join(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf9I5A5DYMLd"
      },
      "source": [
        "number of sentences : n, len(transitions[(word0, word1)] : m\n",
        "## O( n * m * log(m) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rxf1IxhYMLe",
        "outputId": "4acf8533-dc02-4217-8631-80c746545cf2"
      },
      "source": [
        "generate1(25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simply rage and youthful exuberance\n",
            "and at the accolades these skills brung me\n",
            "hes comin home with his neck scratched to catch flack\n",
            "whats one more lie to tell our unborn child\n",
            "my honestys brutal\n",
            "add an ak47 a revolver and a way to get as much shit as you can\n",
            "but i gotta keep a few punchlines\n",
            "this is your moment and hope it dont pass him\n",
            "this whole rhapsody\n",
            "i will not fall\n",
            "me im a doberman pinch yourself\n",
            "so ray j mad\n",
            "into the motherfuckin rock n\n",
            "this love triangle left us in a lifetime yo\n",
            "coast to\n",
            "the truth and my lies now are falling like the rain\n",
            "six minutes\n",
            "on im back from the front to the back nod\n",
            "for the wack while im ripping any one of these verses that versus you\n",
            "on the back nod\n",
            "and not be a king\n",
            "and i know that\n",
            "and she just wants to exact revenge and get that motivation to not give up\n",
            "you fags think its all a game\n",
            "i dont want to admit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwahAp-LYMLe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
